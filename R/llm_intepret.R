#' Interpret Epidemiological Data or Visualisations using LLMs
#'
#' This function interprets a given data frame or ggplot visualisation by sending it to a language model API via the elmer package. It supports multiple LLM providers, allowing users to specify the desired provider and model through environment variables.
#'
#' @param input An input object, either a data frame or a ggplot object, representing the data or visualization to be interpreted.
#' @param word_limit Integer. The desired word length for the response. Defaults to 100.
#' @param prompt_extension Character. Optional additional instructions to extend the standard prompt. Defaults to NULL.
#' @return A character string containing the narrative or interpretation of the input object as generated by the LLM.
#' @details
#' **Supported LLM Providers and Models:**
#' - **OpenAI**: Utilizes OpenAI's models via `chat_openai()`. Requires setting the `OPENAI_API_KEY` environment variable. Applicable models include:
#'   - `"gpt-4o"`
#'   - `"gpt-4o-mini"`
#'   - `"o1-mini"`
#' - **Google Gemini**: Utilizes Google's Gemini models via `chat_gemini()`. Requires setting the `GOOGLE_API_KEY` environment variable. Applicable models include:
#'   - `"gemini-1.5-flash"`
#' - **Amazon Bedrock**: Utilizes Amazon Bedrock models via `chat_bedrock()`. Requires setting the `BEDROCK_API_KEY` environment variable. Applicable models include:
#'   - `"bedrock-model-1"`
#' - **Anthropic Claude**: Utilizes Anthropic's Claude models via `chat_claude()`. Requires setting the `CLAUDE_API_KEY` environment variable. Applicable models include:
#'   - `"claude-1"`
#'
#' **Environment Variables:**
#' - `LLM_PROVIDER`: Specifies the LLM provider ("openai", "gemini", "bedrock", "claude").
#' - `LLM_API_KEY`: The API key corresponding to the chosen provider.
#' - `LLM_MODEL`: The model identifier to use.
#'
#' **Note:** Ensure that the appropriate environment variables are set before invoking this function. The function will throw an error if the specified provider is unsupported or if required environment variables are missing.
#'
#' @import ggplot2
#' @importFrom jsonlite toJSON
#' @import ellmer
#' @export
llm_interpret <- function(input,
                          word_limit = 100,
                          prompt_extension = NULL) {
  # Retrieve environment variables
  provider <- Sys.getenv("LLM_PROVIDER")
  api_key <- Sys.getenv("LLM_API_KEY")
  model <- Sys.getenv("LLM_MODEL")

  # Initialize the chat client based on the provider
  chat <- switch(
    provider,
    "openai" = chat_openai(model = model, api_key = api_key),
    "gemini" = chat_gemini(model = model, api_key = api_key),
    "bedrock" = chat_bedrock(model = model),
    "claude" = chat_claude(model = model, api_key = api_key),
    stop("Unsupported LLM provider specified.")
  )
  # Set the system prompt
  chat$set_system_prompt("You are a concise assistant focusing on epidemiologically relevant observations.")

  # Define the standard prompt
  standard_prompt <- paste(
    "Please provide an interpretation focusing on the most epidemiologically relevant observations in",
    word_limit,
    "words or fewer."
  )

  # Append the prompt extension if provided
  if (!is.null(prompt_extension)) {
    standard_prompt <- paste(standard_prompt, prompt_extension)
  }

  # Case: Input is a data frame
  if (is.data.frame(input)) {
    # Convert data frame to JSON
    json_data <- jsonlite::toJSON(input, pretty = TRUE, auto_unbox = TRUE)

    # Send JSON data to the API
    response <- chat$chat(standard_prompt, json_data)

    return(response)
  }
  # Case: Input is a ggplot object
  else if (inherits(input, "ggplot")) {
    # Save the ggplot object as a temporary image
    temp_file <- tempfile(fileext = ".png")
    ggplot2::ggsave(
      temp_file,
      plot = input,
      width = 6,
      height = 4,
      dpi = 300
    )

    # Send image file to the API
    response <- chat$chat(content_image_file(temp_file), standard_prompt)

    # Remove temporary file after use
    unlink(temp_file)

    return(as.character(response))
  }

  # Handle unexpected input types
  else {
    stop("Input must be a data frame or a ggplot object.")
  }
}
