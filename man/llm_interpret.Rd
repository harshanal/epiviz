% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm_interpret.R
\name{llm_interpret}
\alias{llm_interpret}
\title{Interpret Epidemiological Data or Visualisations using LLMs}
\usage{
llm_interpret(input, word_limit = 100, prompt_extension = NULL)
}
\arguments{
\item{input}{An input object, either a data frame or a ggplot object, representing the data or visualization to be interpreted.}

\item{word_limit}{Integer. The desired word length for the response. Defaults to 100.}

\item{prompt_extension}{Character. Optional additional instructions to extend the standard prompt. Defaults to NULL.}
}
\value{
A character string containing the narrative or interpretation of the input object as generated by the LLM.
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#experimental}{\figure{lifecycle-experimental.svg}{options: alt='[Experimental]'}}}{\strong{[Experimental]}}

This function interprets a given data frame or ggplot visualisation by sending it to a language model API via the ellmer package. It supports multiple LLM providers, allowing users to specify the desired provider and model through environment variables.
}
\details{
\strong{Supported LLM Providers and Models:}
\itemize{
\item \strong{OpenAI}: Utilizes OpenAI's models via \code{chat_openai()}. Requires setting the \code{OPENAI_API_KEY} environment variable. Applicable models include:
\itemize{
\item \code{"gpt-4o"}
\item \code{"gpt-4o-mini"}
\item \code{"o1-mini"}
}
\item \strong{Google Gemini}: Utilizes Google's Gemini models via \code{chat_gemini()}. Requires setting the \code{GOOGLE_API_KEY} environment variable. Applicable models include:
\itemize{
\item \code{"gemini-1.5-flash"}
}
\item \strong{Anthropic Claude}: Utilizes Anthropic's Claude models via \code{chat_claude()}. Requires setting the \code{CLAUDE_API_KEY} environment variable. Applicable models include:
\itemize{
\item \code{"claude-1"}
}
}

\strong{Environment Variables:}
\itemize{
\item \code{LLM_PROVIDER}: Specifies the LLM provider ("openai", "gemini", "claude").
\item \code{LLM_API_KEY}: The API key corresponding to the chosen provider.
\item \code{LLM_MODEL}: The model identifier to use.
}

\strong{Note:} Ensure that the appropriate environment variables are set before invoking this function. The function will throw an error if the specified provider is unsupported or if required environment variables are missing.
}
\section{Tested Models}{

As of October 2025, this function has been tested and verified to work with the following models:
\itemize{
\item OpenAI: gpt-4.1-nano
\item Anthropic: claude-sonnet-4-20250514
\item Google Gemini: gemini-2.5-flash-lite
}

Additional models may be tested in the future. Users can provide custom instructions
through the \code{prompt_extension} parameter for specialised analysis requirements.
}

